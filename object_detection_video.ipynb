import cv2
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

config_file = '/content/drive/MyDrive/object detection video/ssd_mobilenet/ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt'
frozen_model = '/content/drive/MyDrive/object detection video/ssd_mobilenet/frozen_inference_graph (2).pb'

model = cv2.dnn_DetectionModel(frozen_model, config_file)

classLabels = []
file_name = '/content/drive/MyDrive/object detection video/ssd_mobilenet/labels.txt'
with open(file_name, 'rt') as fpt:
    classLabels = fpt.read().rstrip('\n').split('\n')


model.setInputSize(320, 320)
model.setInputScale(1.0/127.5)
model.setInputMean((127.5, 127.5, 127.5))
model.setInputSwapRB(True)

cap = cv2.VideoCapture('/content/drive/MyDrive/object detection video/mixkit-couple-walking-hand-in-hand-4661-large.mp4')

if not cap.isOpened():
    cap = cv2.VideoCapture(0)
if not cap.isOpened():
    raise IOError("Cannot open video")

font_scale = 3
font = cv2.FONT_HERSHEY_PLAIN


while True:
    ret, frame = cap.read()

    ClassIndex, confidence, bbox = model.detect(frame, confThreshold=0.5)

    print(ClassIndex)

    if len(ClassIndex) != 0:
       for ClassInd, conf, boxes in zip(ClassIndex.flatten(), confidence.flatten(), bbox):
        if(ClassInd <= 80):
         cv2.rectangle(frame, boxes, (255,0,0), 2)
         cv2.putText(frame, classLabels[ClassInd-1], (boxes[0]+10, boxes[1]+40), font, fontScale=font_scale, color=(0,255,0), thickness=3)

    cv2_imshow( frame)

    if cv2.waitKey(2) & 0xFF == ord('q'):
      break

cap.release()
cv2.destroyAllWindows()
